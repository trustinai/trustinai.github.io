---
layout: project
type: project
published: true
image:  img/bconfcal.png
title: Bayesian Confidence Calibration for Epistemic Uncertainty Modelling
date: 2021
labels:
  - Neural Networks
  - Uncertainty Calibration
summary: We introduce Bayesian confidence calibration - a framework to obtain calibrated confidence estimates in conjunction with an uncertainty of the calibration method. Commonly, Bayesian neural networks (BNN) are used to indicate a network's uncertainty about a certain prediction. BNNs are interpreted as neural networks that use distributions instead of weights for inference. We transfer this idea of using distributions to confidence calibration. For this purpose, we use stochastic variational inference to build a calibration mapping that outputs a probability distribution rather than a single calibrated estimate. Using this approach, we achieve state-of-the-art calibration performance for object detection calibration. 

projecturl: https://trustinai.github.io/bconfcal/
---

